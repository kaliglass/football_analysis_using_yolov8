{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8qxMYQZmXgz",
        "outputId": "e69aca7e-f6fd-4f3b-fae3-6566f0daf9d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install -q \"numpy==1.26.4\"\n",
        "\n",
        "import numpy as np\n",
        "print(\"NumPy version:\", np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRS4oFYKjv4q",
        "outputId": "62a2d916-a6a2-4447-ac12-94ec51f04f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mNumPy version: 1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgZIoz0YTvV-",
        "outputId": "0a96b2c9-4c9b-4888-b9ae-2f2326d39e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.4/99.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.1/190.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.5/95.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.3/304.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.8/280.8 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.7/160.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.6/255.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.3/292.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.7/939.7 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.9/504.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.1/304.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.8/963.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for paho-mqtt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pybase64 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyvips (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\n",
            "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
            "bigframes 2.29.1 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "typeguard 4.4.4 requires typing_extensions>=4.14.0, but you have typing-extensions 4.12.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.6/200.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q inference-gpu\n",
        "!pip install -q onnxruntime-gpu==1.18.0 --index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcuIp4oXBClh",
        "outputId": "9f0fdda1-f355-4bbe-afbf-4e357aecdec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sports (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "bigframes 2.29.1 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -q git+https://github.com/roboflow/sports.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9Bx6Ku_mlVX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3486ce9a-4784-4ba2-e016-20e6103c7a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: supervision 0.27.0\n",
            "Uninstalling supervision-0.27.0:\n",
            "  Successfully uninstalled supervision-0.27.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y supervision && pip install -q supervision>=0.23.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boWlJuuMUfom",
        "outputId": "54a2390c-4738-433a-93e1-a203f3a73e6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12TqauVZ9tLAv8kWxTTBFWtgt2hNQ4_ZF\n",
            "To: /content/0bfacc_0.mp4\n",
            "100% 19.9M/19.9M [00:00<00:00, 37.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19PGw55V8aA6GZu5-Aac5_9mCy3fNxmEf\n",
            "To: /content/2e57b9_0.mp4\n",
            "100% 21.1M/21.1M [00:00<00:00, 41.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OG8K6wqUw9t7lp9ms1M48DxRhwTYciK-\n",
            "To: /content/08fd33_0.mp4\n",
            "100% 19.9M/19.9M [00:00<00:00, 46.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yYPKuXbHsCxqjA9G-S6aeR2Kcnos8RPU\n",
            "To: /content/573e61_0.mp4\n",
            "100% 18.9M/18.9M [00:00<00:00, 71.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vVwjW1dE1drIdd4ZSILfbCGPD4weoNiu\n",
            "To: /content/121364_0.mp4\n",
            "100% 17.2M/17.2M [00:00<00:00, 43.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown -O \"0bfacc_0.mp4\" \"https://drive.google.com/uc?id=12TqauVZ9tLAv8kWxTTBFWtgt2hNQ4_ZF\"\n",
        "!gdown -O \"2e57b9_0.mp4\" \"https://drive.google.com/uc?id=19PGw55V8aA6GZu5-Aac5_9mCy3fNxmEf\"\n",
        "!gdown -O \"08fd33_0.mp4\" \"https://drive.google.com/uc?id=1OG8K6wqUw9t7lp9ms1M48DxRhwTYciK-\"\n",
        "!gdown -O \"573e61_0.mp4\" \"https://drive.google.com/uc?id=1yYPKuXbHsCxqjA9G-S6aeR2Kcnos8RPU\"\n",
        "!gdown -O \"121364_0.mp4\" \"https://drive.google.com/uc?id=1vVwjW1dE1drIdd4ZSILfbCGPD4weoNiu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Rq5-SX9WfsY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"ONNXRUNTIME_EXECUTION_PROVIDERS\"] = \"[CUDAExecutionProvider]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVlyqi7pVFDo"
      },
      "source": [
        "## ball, player, goalkeeper and referee detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "ZV9voyVS6Aqi",
        "outputId": "703f9a19-1104-4873-f1b5-71631a120826"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "All ufuncs must have type `numpy.ufunc`. Received (<ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1788857107.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mROBOFLOW_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ROBOFLOW_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mPLAYER_DETECTION_MODEL_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"football-players-detection-3zvbc-82esz/1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/inference/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;34m\"\"\"Implement lazy loading for module attributes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_LAZY_ATTRIBUTES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_LAZY_ATTRIBUTES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module 'inference' has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/inference/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m\"inference.core.interfaces.stream.inference_pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"InferencePipeline\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     ),\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;34m\"get_model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_import_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inference.models.utils\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \"get_roboflow_model\": lambda: _import_from(\n\u001b[1;32m     16\u001b[0m         \u001b[0;34m\"inference.models.utils\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_roboflow_model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/inference/__init__.py\u001b[0m in \u001b[0;36m_import_from\u001b[0;34m(module_path, attribute_name)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/inference/models/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mUSE_INFERENCE_EXP_MODELS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m from inference.core.models.stubs import (\n\u001b[1;32m     27\u001b[0m     \u001b[0mClassificationModelStub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/inference/core/models/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInferenceResponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprocessReturnMetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musage_tracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0musage_collector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/inference/usage_tracking/collector.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0minference_sdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecution_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mexecution_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/inference_sdk/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0minference_sdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInferenceSDKDeprecationWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minference_sdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInferenceHTTPClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m from inference_sdk.http.entities import (\n\u001b[1;32m      7\u001b[0m     \u001b[0mInferenceConfiguration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/inference_sdk/http/client.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0minference_sdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munwrap_single_element_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m from inference_sdk.http.utils.loaders import (\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mload_nested_batches_of_inference_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mload_static_inference_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/inference_sdk/http/utils/loaders.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msupervision\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/supervision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"development\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m from supervision.annotators.core import (\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mBackgroundOverlayAnnotator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mBlurAnnotator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/supervision/annotators/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplprep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msupervision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseAnnotator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/interpolate/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \"\"\"  # noqa: E501\n\u001b[0;32m--> 192\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_interpolate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_fitpack_py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/interpolate/_interpolate.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearchsorted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy_if_needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/special/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_support_alternative_backends\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_basic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_basic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/special/_basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_specfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_comb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_comb_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from ._multiufuncs import (assoc_legendre_p_all,\n\u001b[0m\u001b[1;32m     23\u001b[0m                            legendre_p_all)\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/special/_multiufuncs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m sph_legendre_p = MultiUFunc(\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0msph_legendre_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     r\"\"\"sph_legendre_p(n, m, theta, *, diff_n=0)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/special/_multiufuncs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ufunc_or_ufuncs, doc, force_complex_output, **default_kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mufunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mufuncs_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                     raise ValueError(\"All ufuncs must have type `numpy.ufunc`.\"\n\u001b[0m\u001b[1;32m     42\u001b[0m                                      f\" Received {ufunc_or_ufuncs}\")\n\u001b[1;32m     43\u001b[0m                 \u001b[0mseen_input_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"->\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All ufuncs must have type `numpy.ufunc`. Received (<ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>)"
          ]
        }
      ],
      "source": [
        "from inference import get_model\n",
        "from google.colab import userdata\n",
        "\n",
        "ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
        "PLAYER_DETECTION_MODEL_ID = \"football-players-detection-3zvbc-82esz/1\"\n",
        "PLAYER_DETECTION_MODEL = get_model(model_id=PLAYER_DETECTION_MODEL_ID, api_key=ROBOFLOW_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz-hd4mdZ4UD"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "sv.plot_image(frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duGEOk-j4n4i"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "\n",
        "box_annotator = sv.BoxAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#FF8C00', '#00BFFF', '#FF1493', '#FFD700']),\n",
        "    thickness=2\n",
        ")\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#FF8C00', '#00BFFF', '#FF1493', '#FFD700']),\n",
        "    text_color=sv.Color.from_hex('#000000')\n",
        ")\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "detections = sv.Detections.from_inference(result)\n",
        "\n",
        "labels = [\n",
        "    f\"{class_name} {confidence:.2f}\"\n",
        "    for class_name, confidence\n",
        "    in zip(detections['class_name'], detections.confidence)\n",
        "]\n",
        "\n",
        "annotated_frame = frame.copy()\n",
        "annotated_frame = box_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=detections)\n",
        "annotated_frame = label_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=detections,\n",
        "    labels=labels)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-4F9NB48U1_"
      },
      "source": [
        "[link text](https://)## video game style visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWoDdvikt4TR"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "BALL_ID = 0\n",
        "\n",
        "ellipse_annotator = sv.EllipseAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    thickness=2\n",
        ")\n",
        "triangle_annotator = sv.TriangleAnnotator(\n",
        "    color=sv.Color.from_hex('#FFD700'),\n",
        "    base=25,\n",
        "    height=21,\n",
        "    outline_thickness=1\n",
        ")\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "detections = sv.Detections.from_inference(result)\n",
        "\n",
        "ball_detections = detections[detections.class_id == BALL_ID]\n",
        "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
        "\n",
        "all_detections = detections[detections.class_id != BALL_ID]\n",
        "all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
        "all_detections.class_id -= 1\n",
        "\n",
        "annotated_frame = frame.copy()\n",
        "annotated_frame = ellipse_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=all_detections)\n",
        "annotated_frame = triangle_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=ball_detections)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNRVUGG4nz_J"
      },
      "source": [
        "## player tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ixZlM06Gmae"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "BALL_ID = 0\n",
        "\n",
        "ellipse_annotator = sv.EllipseAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    thickness=2\n",
        ")\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    text_color=sv.Color.from_hex('#000000'),\n",
        "    text_position=sv.Position.BOTTOM_CENTER\n",
        ")\n",
        "triangle_annotator = sv.TriangleAnnotator(\n",
        "    color=sv.Color.from_hex('#FFD700'),\n",
        "    base=25,\n",
        "    height=21,\n",
        "    outline_thickness=1\n",
        ")\n",
        "\n",
        "tracker = sv.ByteTrack()\n",
        "tracker.reset()\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "detections = sv.Detections.from_inference(result)\n",
        "\n",
        "ball_detections = detections[detections.class_id == BALL_ID]\n",
        "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
        "\n",
        "all_detections = detections[detections.class_id != BALL_ID]\n",
        "all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
        "all_detections.class_id -= 1\n",
        "all_detections = tracker.update_with_detections(detections=all_detections)\n",
        "\n",
        "labels = [\n",
        "    f\"#{tracker_id}\"\n",
        "    for tracker_id\n",
        "    in all_detections.tracker_id\n",
        "]\n",
        "\n",
        "annotated_frame = frame.copy()\n",
        "annotated_frame = ellipse_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=all_detections)\n",
        "annotated_frame = label_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=all_detections,\n",
        "    labels=labels)\n",
        "annotated_frame = triangle_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=ball_detections)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mr2smM9fMTSO"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "PLAYER_ID = 2\n",
        "STRIDE = 30\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(\n",
        "    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)\n",
        "\n",
        "crops = []\n",
        "for frame in tqdm(frame_generator, desc='collecting crops'):\n",
        "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "    detections = sv.Detections.from_inference(result)\n",
        "    detections = detections.with_nms(threshold=0.5, class_agnostic=True)\n",
        "    detections = detections[detections.class_id == PLAYER_ID]\n",
        "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]\n",
        "    crops += players_crops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmUMuTiq4_pT"
      },
      "source": [
        "**Note:** Here's a sample (100 elements) of the crops we've gathered."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qImyErnMNhfC"
      },
      "outputs": [],
      "source": [
        "sv.plot_images_grid(crops[:100], grid_size=(10, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8COwN7TweZpK"
      },
      "source": [
        "**Note:** Next, we'll run [SigLIP](https://huggingface.co/docs/transformers/en/model_doc/siglip) to calculate embeddings for each of the crops."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLcvVFrbOey8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, SiglipVisionModel\n",
        "\n",
        "SIGLIP_MODEL_PATH = 'google/siglip-base-patch16-224'\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "EMBEDDINGS_MODEL = SiglipVisionModel.from_pretrained(SIGLIP_MODEL_PATH).to(DEVICE)\n",
        "EMBEDDINGS_PROCESSOR = AutoProcessor.from_pretrained(SIGLIP_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrn67xnEQZzM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from more_itertools import chunked\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "crops = [sv.cv2_to_pillow(crop) for crop in crops]\n",
        "batches = chunked(crops, BATCH_SIZE)\n",
        "data = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(batches, desc='embedding extraction'):\n",
        "        inputs = EMBEDDINGS_PROCESSOR(images=batch, return_tensors=\"pt\").to(DEVICE)\n",
        "        outputs = EMBEDDINGS_MODEL(**inputs)\n",
        "        embeddings = torch.mean(outputs.last_hidden_state, dim=1).cpu().numpy()\n",
        "        data.append(embeddings)\n",
        "\n",
        "data = np.concatenate(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1QUD1X25faA"
      },
      "source": [
        "**Note:** Using [UMAP](https://github.com/lmcinnes/umap), we project our embeddings from `(N, 768)` to `(N, 3)` and then perform a two-cluster division using [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EXV02O3SWsX"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "REDUCER = umap.UMAP(n_components=3)\n",
        "CLUSTERING_MODEL = KMeans(n_clusters=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfrRj4_PS1HD"
      },
      "outputs": [],
      "source": [
        "projections = REDUCER.fit_transform(data)\n",
        "clusters = CLUSTERING_MODEL.fit_predict(projections)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_gqJjBu6IRU"
      },
      "source": [
        "**Note:** Here's an interactive visualization of our results. Click on a dot to display its associated crop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXWLoCBtfPDH"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "from typing import Dict, List\n",
        "from IPython.core.display import display, HTML\n",
        "from PIL import Image\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "\n",
        "def pil_image_to_data_uri(image: Image.Image) -> str:\n",
        "    buffered = BytesIO()\n",
        "    image.save(buffered, format=\"PNG\")\n",
        "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "    return f\"data:image/png;base64,{img_str}\"\n",
        "\n",
        "\n",
        "def display_projections(\n",
        "    labels: np.ndarray,\n",
        "    projections: np.ndarray,\n",
        "    images: List[Image.Image],\n",
        "    show_legend: bool = False,\n",
        "    show_markers_with_text: bool = True\n",
        ") -> None:\n",
        "    image_data_uris = {f\"image_{i}\": pil_image_to_data_uri(image) for i, image in enumerate(images)}\n",
        "    image_ids = np.array([f\"image_{i}\" for i in range(len(images))])\n",
        "\n",
        "    unique_labels = np.unique(labels)\n",
        "    traces = []\n",
        "    for unique_label in unique_labels:\n",
        "        mask = labels == unique_label\n",
        "        customdata_masked = image_ids[mask]\n",
        "        trace = go.Scatter3d(\n",
        "            x=projections[mask][:, 0],\n",
        "            y=projections[mask][:, 1],\n",
        "            z=projections[mask][:, 2],\n",
        "            mode='markers+text' if show_markers_with_text else 'markers',\n",
        "            text=labels[mask],\n",
        "            customdata=customdata_masked,\n",
        "            name=str(unique_label),\n",
        "            marker=dict(size=8),\n",
        "            hovertemplate=\"<b>class: %{text}</b><br>image ID: %{customdata}<extra></extra>\"\n",
        "        )\n",
        "        traces.append(trace)\n",
        "\n",
        "    fig = go.Figure(data=traces)\n",
        "    fig.update_layout(\n",
        "        scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'),\n",
        "        width=1000,\n",
        "        height=1000,\n",
        "        showlegend=show_legend\n",
        "    )\n",
        "\n",
        "    plotly_div = fig.to_html(full_html=False, include_plotlyjs=False, div_id=\"scatter-plot-3d\")\n",
        "\n",
        "    javascript_code = f\"\"\"\n",
        "    <script>\n",
        "        function displayImage(imageId) {{\n",
        "            var imageElement = document.getElementById('image-display');\n",
        "            var placeholderText = document.getElementById('placeholder-text');\n",
        "            var imageDataURIs = {image_data_uris};\n",
        "            imageElement.src = imageDataURIs[imageId];\n",
        "            imageElement.style.display = 'block';\n",
        "            placeholderText.style.display = 'none';\n",
        "        }}\n",
        "\n",
        "        var chartElement = document.getElementById('scatter-plot-3d');\n",
        "\n",
        "        chartElement.on('plotly_click', function(data) {{\n",
        "            var customdata = data.points[0].customdata;\n",
        "            displayImage(customdata);\n",
        "        }});\n",
        "    </script>\n",
        "    \"\"\"\n",
        "\n",
        "    html_template = f\"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html>\n",
        "        <head>\n",
        "            <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
        "            <style>\n",
        "                #image-container {{\n",
        "                    position: fixed;\n",
        "                    top: 0;\n",
        "                    left: 0;\n",
        "                    width: 200px;\n",
        "                    height: 200px;\n",
        "                    padding: 5px;\n",
        "                    border: 1px solid #ccc;\n",
        "                    background-color: white;\n",
        "                    z-index: 1000;\n",
        "                    box-sizing: border-box;\n",
        "                    display: flex;\n",
        "                    align-items: center;\n",
        "                    justify-content: center;\n",
        "                    text-align: center;\n",
        "                }}\n",
        "                #image-display {{\n",
        "                    width: 100%;\n",
        "                    height: 100%;\n",
        "                    object-fit: contain;\n",
        "                }}\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            {plotly_div}\n",
        "            <div id=\"image-container\">\n",
        "                <img id=\"image-display\" src=\"\" alt=\"Selected image\" style=\"display: none;\" />\n",
        "                <p id=\"placeholder-text\">Click on a data entry to display an image</p>\n",
        "            </div>\n",
        "            {javascript_code}\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "    display(HTML(html_template))\n",
        "\n",
        "display_projections(clusters, projections, crops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZG1DorZ8lSQ"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "from tqdm import tqdm\n",
        "from sports.common.team import TeamClassifier\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "PLAYER_ID = 2\n",
        "STRIDE = 30\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(\n",
        "    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)\n",
        "\n",
        "crops = []\n",
        "for frame in tqdm(frame_generator, desc='collecting crops'):\n",
        "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "    detections = sv.Detections.from_inference(result)\n",
        "    players_detections = detections[detections.class_id == PLAYER_ID]\n",
        "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]\n",
        "    crops += players_crops\n",
        "\n",
        "team_classifier = TeamClassifier(device=\"cuda\")\n",
        "team_classifier.fit(crops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlHrjbIf-Yrk"
      },
      "source": [
        "**Note:** Time to assign goalkeepers to teams. We'll use a simple heuristic: calculate the average position (centroid) of the players belonging to both teams and then assign the goalkeeper to the team whose average position is closer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qx_4g2DGC1Bd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "def resolve_goalkeepers_team_id(\n",
        "    players: sv.Detections,\n",
        "    goalkeepers: sv.Detections\n",
        ") -> np.ndarray:\n",
        "    goalkeepers_xy = goalkeepers.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
        "    players_xy = players.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
        "    team_0_centroid = players_xy[players.class_id == 0].mean(axis=0)\n",
        "    team_1_centroid = players_xy[players.class_id == 1].mean(axis=0)\n",
        "    goalkeepers_team_id = []\n",
        "    for goalkeeper_xy in goalkeepers_xy:\n",
        "        dist_0 = np.linalg.norm(goalkeeper_xy - team_0_centroid)\n",
        "        dist_1 = np.linalg.norm(goalkeeper_xy - team_1_centroid)\n",
        "        goalkeepers_team_id.append(0 if dist_0 < dist_1 else 1)\n",
        "\n",
        "    return np.array(goalkeepers_team_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwmQrEOHAPyi"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "BALL_ID = 0\n",
        "GOALKEEPER_ID = 1\n",
        "PLAYER_ID = 2\n",
        "REFEREE_ID = 3\n",
        "\n",
        "ellipse_annotator = sv.EllipseAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    thickness=2\n",
        ")\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    text_color=sv.Color.from_hex('#000000'),\n",
        "    text_position=sv.Position.BOTTOM_CENTER\n",
        ")\n",
        "triangle_annotator = sv.TriangleAnnotator(\n",
        "    color=sv.Color.from_hex('#FFD700'),\n",
        "    base=25,\n",
        "    height=21,\n",
        "    outline_thickness=1\n",
        ")\n",
        "\n",
        "tracker = sv.ByteTrack()\n",
        "tracker.reset()\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "detections = sv.Detections.from_inference(result)\n",
        "\n",
        "ball_detections = detections[detections.class_id == BALL_ID]\n",
        "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
        "\n",
        "all_detections = detections[detections.class_id != BALL_ID]\n",
        "all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
        "all_detections = tracker.update_with_detections(detections=all_detections)\n",
        "\n",
        "goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
        "players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
        "referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
        "\n",
        "players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
        "players_detections.class_id = team_classifier.predict(players_crops)\n",
        "\n",
        "goalkeepers_detections.class_id = resolve_goalkeepers_team_id(\n",
        "    players_detections, goalkeepers_detections)\n",
        "\n",
        "referees_detections.class_id -= 1\n",
        "\n",
        "all_detections = sv.Detections.merge([\n",
        "    players_detections, goalkeepers_detections, referees_detections])\n",
        "\n",
        "labels = [\n",
        "    f\"#{tracker_id}\"\n",
        "    for tracker_id\n",
        "    in all_detections.tracker_id\n",
        "]\n",
        "\n",
        "all_detections.class_id = all_detections.class_id.astype(int)\n",
        "\n",
        "annotated_frame = frame.copy()\n",
        "annotated_frame = ellipse_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=all_detections)\n",
        "annotated_frame = label_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=all_detections,\n",
        "    labels=labels)\n",
        "annotated_frame = triangle_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=ball_detections)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4F_9d1YHKuj"
      },
      "source": [
        "## pitch keypoint detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts9f1goyCPEa"
      },
      "outputs": [],
      "source": [
        "from inference import get_model\n",
        "from google.colab import userdata\n",
        "\n",
        "ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
        "FIELD_DETECTION_MODEL_ID = \"football-field-detection-f07vi/14\"\n",
        "FIELD_DETECTION_MODEL = get_model(model_id=FIELD_DETECTION_MODEL_ID, api_key=ROBOFLOW_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhiFgOGkUky5"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "\n",
        "vertex_annotator = sv.VertexAnnotator(\n",
        "    color=sv.Color.from_hex('#FF1493'),\n",
        "    radius=8)\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "key_points = sv.KeyPoints.from_inference(result)\n",
        "\n",
        "annotated_frame = frame.copy()\n",
        "annotated_frame = vertex_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    key_points=key_points)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HAVEmruAGpQ"
      },
      "source": [
        "**Note:** Notice that some of the keypoints we detected are in incorrect locations. These are keypoints with a low confidence level. Let's filter out these keypoints and keep only the ones the model is confident about."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWhRsjoZGRUa"
      },
      "source": [
        "## filter low confidence keypoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4XW4_bDGjlF"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "\n",
        "vertex_annotator = sv.VertexAnnotator(\n",
        "    color=sv.Color.from_hex('#FF1493'),\n",
        "    radius=8)\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, start=200)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "key_points = sv.KeyPoints.from_inference(result)\n",
        "\n",
        "filter = key_points.confidence[0] > 0.5\n",
        "frame_reference_points = key_points.xy[0][filter]\n",
        "frame_reference_key_points = sv.KeyPoints(\n",
        "    xy=frame_reference_points[np.newaxis, ...])\n",
        "\n",
        "annotated_frame = frame.copy()\n",
        "annotated_frame = vertex_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    key_points=frame_reference_key_points)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7SUQtqbZ5QJ"
      },
      "source": [
        "## project pitch lines on frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojlmrERnBAIN"
      },
      "source": [
        "**Note:** The [sports](https://github.com/roboflow/sports) repository contains a [`SoccerPitchConfiguration`](https://github.com/roboflow/sports/blob/06053616f1f8a8ae1fa936eb00dcdc2e4f888bb1/sports/configs/soccer.py#L6) that provides information about the real-world geometry of the soccer pitch. It also includes utilities for visualizing elements located on the pitch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5y4tMWbaiC6"
      },
      "outputs": [],
      "source": [
        "from sports.annotators.soccer import draw_pitch\n",
        "from sports.configs.soccer import SoccerPitchConfiguration\n",
        "\n",
        "CONFIG = SoccerPitchConfiguration()\n",
        "\n",
        "annotated_frame = draw_pitch(CONFIG)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1abHrITPB3Bd"
      },
      "source": [
        "**Note:** It's time to utilize the keypoint pairs located on the camera perspective plane and the football pitch plane. The [sports](https://github.com/roboflow/sports) repository includes a [`ViewTransformer`](https://github.com/roboflow/sports/blob/06053616f1f8a8ae1fa936eb00dcdc2e4f888bb1/sports/common/view.py#L7), which employs homography for perspective transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjoG33jod7M8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "from sports.common.view import ViewTransformer\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "\n",
        "edge_annotator = sv.EdgeAnnotator(\n",
        "    color=sv.Color.from_hex('#00BFFF'),\n",
        "    thickness=2, edges=CONFIG.edges)\n",
        "vertex_annotator = sv.VertexAnnotator(\n",
        "    color=sv.Color.from_hex('#FF1493'),\n",
        "    radius=8)\n",
        "vertex_annotator_2 = sv.VertexAnnotator(\n",
        "    color=sv.Color.from_hex('#00BFFF'),\n",
        "    radius=8)\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, start=200)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "key_points = sv.KeyPoints.from_inference(result)\n",
        "\n",
        "filter = key_points.confidence[0] > 0.5\n",
        "frame_reference_points = key_points.xy[0][filter]\n",
        "frame_reference_key_points = sv.KeyPoints(\n",
        "    xy=frame_reference_points[np.newaxis, ...])\n",
        "\n",
        "pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
        "\n",
        "transformer = ViewTransformer(\n",
        "    source=pitch_reference_points,\n",
        "    target=frame_reference_points\n",
        ")\n",
        "\n",
        "pitch_all_points = np.array(CONFIG.vertices)\n",
        "frame_all_points = transformer.transform_points(points=pitch_all_points)\n",
        "\n",
        "frame_all_key_points = sv.KeyPoints(xy=frame_all_points[np.newaxis, ...])\n",
        "\n",
        "annotated_frame = frame.copy()\n",
        "annotated_frame = edge_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    key_points=frame_all_key_points)\n",
        "annotated_frame = vertex_annotator_2.annotate(\n",
        "    scene=annotated_frame,\n",
        "    key_points=frame_all_key_points)\n",
        "annotated_frame = vertex_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    key_points=frame_reference_key_points)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oMXo5k3HkzD"
      },
      "source": [
        "## project ball, players and referies on pitch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9nRbJnksPyE"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "from tqdm import tqdm\n",
        "from sports.common.team import TeamClassifier\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "PLAYER_ID = 2\n",
        "STRIDE = 30\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(\n",
        "    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)\n",
        "\n",
        "crops = []\n",
        "for frame in tqdm(frame_generator, desc='collecting crops'):\n",
        "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "    detections = sv.Detections.from_inference(result)\n",
        "    players_detections = detections[detections.class_id == PLAYER_ID]\n",
        "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]\n",
        "    crops += players_crops\n",
        "\n",
        "team_classifier = TeamClassifier(device=\"cuda\")\n",
        "team_classifier.fit(crops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0s4SjLIJUwM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from typing import Optional\n",
        "\n",
        "def draw_pitch_voronoi_diagram_2(\n",
        "    config: SoccerPitchConfiguration,\n",
        "    team_1_xy: np.ndarray,\n",
        "    team_2_xy: np.ndarray,\n",
        "    team_1_color: sv.Color = sv.Color.RED,\n",
        "    team_2_color: sv.Color = sv.Color.WHITE,\n",
        "    opacity: float = 0.5,\n",
        "    padding: int = 50,\n",
        "    scale: float = 0.1,\n",
        "    pitch: Optional[np.ndarray] = None\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Draws a Voronoi diagram on a soccer pitch representing the control areas of two\n",
        "    teams with smooth color transitions.\n",
        "\n",
        "    Args:\n",
        "        config (SoccerPitchConfiguration): Configuration object containing the\n",
        "            dimensions and layout of the pitch.\n",
        "        team_1_xy (np.ndarray): Array of (x, y) coordinates representing the positions\n",
        "            of players in team 1.\n",
        "        team_2_xy (np.ndarray): Array of (x, y) coordinates representing the positions\n",
        "            of players in team 2.\n",
        "        team_1_color (sv.Color, optional): Color representing the control area of\n",
        "            team 1. Defaults to sv.Color.RED.\n",
        "        team_2_color (sv.Color, optional): Color representing the control area of\n",
        "            team 2. Defaults to sv.Color.WHITE.\n",
        "        opacity (float, optional): Opacity of the Voronoi diagram overlay.\n",
        "            Defaults to 0.5.\n",
        "        padding (int, optional): Padding around the pitch in pixels.\n",
        "            Defaults to 50.\n",
        "        scale (float, optional): Scaling factor for the pitch dimensions.\n",
        "            Defaults to 0.1.\n",
        "        pitch (Optional[np.ndarray], optional): Existing pitch image to draw the\n",
        "            Voronoi diagram on. If None, a new pitch will be created. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Image of the soccer pitch with the Voronoi diagram overlay.\n",
        "    \"\"\"\n",
        "    if pitch is None:\n",
        "        pitch = draw_pitch(\n",
        "            config=config,\n",
        "            padding=padding,\n",
        "            scale=scale\n",
        "        )\n",
        "\n",
        "    scaled_width = int(config.width * scale)\n",
        "    scaled_length = int(config.length * scale)\n",
        "\n",
        "    voronoi = np.zeros_like(pitch, dtype=np.uint8)\n",
        "\n",
        "    team_1_color_bgr = np.array(team_1_color.as_bgr(), dtype=np.uint8)\n",
        "    team_2_color_bgr = np.array(team_2_color.as_bgr(), dtype=np.uint8)\n",
        "\n",
        "    y_coordinates, x_coordinates = np.indices((\n",
        "        scaled_width + 2 * padding,\n",
        "        scaled_length + 2 * padding\n",
        "    ))\n",
        "\n",
        "    y_coordinates -= padding\n",
        "    x_coordinates -= padding\n",
        "\n",
        "    def calculate_distances(xy, x_coordinates, y_coordinates):\n",
        "        return np.sqrt((xy[:, 0][:, None, None] * scale - x_coordinates) ** 2 +\n",
        "                       (xy[:, 1][:, None, None] * scale - y_coordinates) ** 2)\n",
        "\n",
        "    distances_team_1 = calculate_distances(team_1_xy, x_coordinates, y_coordinates)\n",
        "    distances_team_2 = calculate_distances(team_2_xy, x_coordinates, y_coordinates)\n",
        "\n",
        "    min_distances_team_1 = np.min(distances_team_1, axis=0)\n",
        "    min_distances_team_2 = np.min(distances_team_2, axis=0)\n",
        "\n",
        "    # Increase steepness of the blend effect\n",
        "    steepness = 15  # Increased steepness for sharper transition\n",
        "    distance_ratio = min_distances_team_2 / np.clip(min_distances_team_1 + min_distances_team_2, a_min=1e-5, a_max=None)\n",
        "    blend_factor = np.tanh((distance_ratio - 0.5) * steepness) * 0.5 + 0.5\n",
        "\n",
        "    # Create the smooth color transition\n",
        "    for c in range(3):  # Iterate over the B, G, R channels\n",
        "        voronoi[:, :, c] = (blend_factor * team_1_color_bgr[c] +\n",
        "                            (1 - blend_factor) * team_2_color_bgr[c]).astype(np.uint8)\n",
        "\n",
        "    overlay = cv2.addWeighted(voronoi, opacity, pitch, 1 - opacity, 0)\n",
        "\n",
        "    return overlay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rjfNfzErrSN"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "from sports.annotators.soccer import (\n",
        "    draw_pitch,\n",
        "    draw_points_on_pitch,\n",
        "    draw_pitch_voronoi_diagram\n",
        ")\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "BALL_ID = 0\n",
        "GOALKEEPER_ID = 1\n",
        "PLAYER_ID = 2\n",
        "REFEREE_ID = 3\n",
        "\n",
        "ellipse_annotator = sv.EllipseAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    thickness=2\n",
        ")\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    text_color=sv.Color.from_hex('#000000'),\n",
        "    text_position=sv.Position.BOTTOM_CENTER\n",
        ")\n",
        "triangle_annotator = sv.TriangleAnnotator(\n",
        "    color=sv.Color.from_hex('#FFD700'),\n",
        "    base=20, height=17\n",
        ")\n",
        "\n",
        "tracker = sv.ByteTrack()\n",
        "tracker.reset()\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "# ball, goalkeeper, player, referee detection\n",
        "\n",
        "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "detections = sv.Detections.from_inference(result)\n",
        "\n",
        "ball_detections = detections[detections.class_id == BALL_ID]\n",
        "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
        "\n",
        "all_detections = detections[detections.class_id != BALL_ID]\n",
        "all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
        "all_detections = tracker.update_with_detections(detections=all_detections)\n",
        "\n",
        "goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
        "players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
        "referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
        "\n",
        "# team assignment\n",
        "\n",
        "players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
        "players_detections.class_id = team_classifier.predict(players_crops)\n",
        "\n",
        "goalkeepers_detections.class_id = resolve_goalkeepers_team_id(\n",
        "    players_detections, goalkeepers_detections)\n",
        "\n",
        "referees_detections.class_id -= 1\n",
        "\n",
        "all_detections = sv.Detections.merge([\n",
        "    players_detections, goalkeepers_detections, referees_detections])\n",
        "\n",
        "# frame visualization\n",
        "\n",
        "labels = [\n",
        "    f\"#{tracker_id}\"\n",
        "    for tracker_id\n",
        "    in all_detections.tracker_id\n",
        "]\n",
        "\n",
        "all_detections.class_id = all_detections.class_id.astype(int)\n",
        "\n",
        "annotated_frame = frame.copy()\n",
        "annotated_frame = ellipse_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=all_detections)\n",
        "annotated_frame = label_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=all_detections,\n",
        "    labels=labels)\n",
        "annotated_frame = triangle_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=ball_detections)\n",
        "\n",
        "sv.plot_image(annotated_frame)\n",
        "\n",
        "players_detections = sv.Detections.merge([\n",
        "    players_detections, goalkeepers_detections\n",
        "])\n",
        "\n",
        "# detect pitch key points\n",
        "\n",
        "result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "key_points = sv.KeyPoints.from_inference(result)\n",
        "\n",
        "# project ball, players and referies on pitch\n",
        "\n",
        "filter = key_points.confidence[0] > 0.5\n",
        "frame_reference_points = key_points.xy[0][filter]\n",
        "pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
        "\n",
        "transformer = ViewTransformer(\n",
        "    source=frame_reference_points,\n",
        "    target=pitch_reference_points\n",
        ")\n",
        "\n",
        "frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
        "pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)\n",
        "\n",
        "players_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
        "pitch_players_xy = transformer.transform_points(points=players_xy)\n",
        "\n",
        "referees_xy = referees_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
        "pitch_referees_xy = transformer.transform_points(points=referees_xy)\n",
        "\n",
        "# visualize video game-style radar view\n",
        "\n",
        "annotated_frame = draw_pitch(CONFIG)\n",
        "annotated_frame = draw_points_on_pitch(\n",
        "    config=CONFIG,\n",
        "    xy=pitch_ball_xy,\n",
        "    face_color=sv.Color.WHITE,\n",
        "    edge_color=sv.Color.BLACK,\n",
        "    radius=10,\n",
        "    pitch=annotated_frame)\n",
        "annotated_frame = draw_points_on_pitch(\n",
        "    config=CONFIG,\n",
        "    xy=pitch_players_xy[players_detections.class_id == 0],\n",
        "    face_color=sv.Color.from_hex('00BFFF'),\n",
        "    edge_color=sv.Color.BLACK,\n",
        "    radius=16,\n",
        "    pitch=annotated_frame)\n",
        "annotated_frame = draw_points_on_pitch(\n",
        "    config=CONFIG,\n",
        "    xy=pitch_players_xy[players_detections.class_id == 1],\n",
        "    face_color=sv.Color.from_hex('FF1493'),\n",
        "    edge_color=sv.Color.BLACK,\n",
        "    radius=16,\n",
        "    pitch=annotated_frame)\n",
        "annotated_frame = draw_points_on_pitch(\n",
        "    config=CONFIG,\n",
        "    xy=pitch_referees_xy,\n",
        "    face_color=sv.Color.from_hex('FFD700'),\n",
        "    edge_color=sv.Color.BLACK,\n",
        "    radius=16,\n",
        "    pitch=annotated_frame)\n",
        "\n",
        "sv.plot_image(annotated_frame)\n",
        "\n",
        "# visualize voronoi diagram\n",
        "\n",
        "annotated_frame = draw_pitch(CONFIG)\n",
        "annotated_frame = draw_pitch_voronoi_diagram(\n",
        "    config=CONFIG,\n",
        "    team_1_xy=pitch_players_xy[players_detections.class_id == 0],\n",
        "    team_2_xy=pitch_players_xy[players_detections.class_id == 1],\n",
        "    team_1_color=sv.Color.from_hex('00BFFF'),\n",
        "    team_2_color=sv.Color.from_hex('FF1493'),\n",
        "    pitch=annotated_frame)\n",
        "\n",
        "sv.plot_image(annotated_frame)\n",
        "\n",
        "# visualize voronoi diagram with blend\n",
        "\n",
        "annotated_frame = draw_pitch(\n",
        "    config=CONFIG,\n",
        "    background_color=sv.Color.WHITE,\n",
        "    line_color=sv.Color.BLACK\n",
        ")\n",
        "annotated_frame = draw_pitch_voronoi_diagram_2(\n",
        "    config=CONFIG,\n",
        "    team_1_xy=pitch_players_xy[players_detections.class_id == 0],\n",
        "    team_2_xy=pitch_players_xy[players_detections.class_id == 1],\n",
        "    team_1_color=sv.Color.from_hex('00BFFF'),\n",
        "    team_2_color=sv.Color.from_hex('FF1493'),\n",
        "    pitch=annotated_frame)\n",
        "annotated_frame = draw_points_on_pitch(\n",
        "    config=CONFIG,\n",
        "    xy=pitch_ball_xy,\n",
        "    face_color=sv.Color.WHITE,\n",
        "    edge_color=sv.Color.WHITE,\n",
        "    radius=8,\n",
        "    thickness=1,\n",
        "    pitch=annotated_frame)\n",
        "annotated_frame = draw_points_on_pitch(\n",
        "    config=CONFIG,\n",
        "    xy=pitch_players_xy[players_detections.class_id == 0],\n",
        "    face_color=sv.Color.from_hex('00BFFF'),\n",
        "    edge_color=sv.Color.WHITE,\n",
        "    radius=16,\n",
        "    thickness=1,\n",
        "    pitch=annotated_frame)\n",
        "annotated_frame = draw_points_on_pitch(\n",
        "    config=CONFIG,\n",
        "    xy=pitch_players_xy[players_detections.class_id == 1],\n",
        "    face_color=sv.Color.from_hex('FF1493'),\n",
        "    edge_color=sv.Color.WHITE,\n",
        "    radius=16,\n",
        "    thickness=1,\n",
        "    pitch=annotated_frame)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ7CP3RFoX4R"
      },
      "source": [
        "## ball tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFMa2ER_JUtG"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "import supervision as sv\n",
        "from sports.annotators.soccer import draw_pitch, draw_points_on_pitch\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "BALL_ID = 0\n",
        "MAXLEN = 5\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "path_raw = []\n",
        "M = deque(maxlen=MAXLEN)\n",
        "\n",
        "for frame in tqdm(frame_generator, total=video_info.total_frames):\n",
        "\n",
        "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "    detections = sv.Detections.from_inference(result)\n",
        "\n",
        "    ball_detections = detections[detections.class_id == BALL_ID]\n",
        "    ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
        "\n",
        "    result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "    key_points = sv.KeyPoints.from_inference(result)\n",
        "\n",
        "    filter = key_points.confidence[0] > 0.5\n",
        "    frame_reference_points = key_points.xy[0][filter]\n",
        "    pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
        "\n",
        "    transformer = ViewTransformer(\n",
        "        source=frame_reference_points,\n",
        "        target=pitch_reference_points\n",
        "    )\n",
        "    M.append(transformer.m)\n",
        "    transformer.m = np.mean(np.array(M), axis=0)\n",
        "\n",
        "    frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
        "    pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)\n",
        "\n",
        "    path_raw.append(pitch_ball_xy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAD53KnFp8dw"
      },
      "outputs": [],
      "source": [
        "path = [\n",
        "    np.empty((0, 2), dtype=np.float32) if coorinates.shape[0] >= 2 else coorinates\n",
        "    for coorinates\n",
        "    in path_raw\n",
        "]\n",
        "\n",
        "path = [coorinates.flatten() for coorinates in path]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwiq0zIAq2JE"
      },
      "outputs": [],
      "source": [
        "from sports.annotators.soccer import draw_paths_on_pitch\n",
        "\n",
        "annotated_frame = draw_pitch(CONFIG)\n",
        "annotated_frame = draw_paths_on_pitch(\n",
        "    config=CONFIG,\n",
        "    paths=[path],\n",
        "    color=sv.Color.WHITE,\n",
        "    pitch=annotated_frame)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWksgzo4q5cr"
      },
      "outputs": [],
      "source": [
        "from typing import List, Union\n",
        "\n",
        "def replace_outliers_based_on_distance(\n",
        "    positions: List[np.ndarray],\n",
        "    distance_threshold: float\n",
        ") -> List[np.ndarray]:\n",
        "    last_valid_position: Union[np.ndarray, None] = None\n",
        "    cleaned_positions: List[np.ndarray] = []\n",
        "\n",
        "    for position in positions:\n",
        "        if len(position) == 0:\n",
        "            # If the current position is already empty, just add it to the cleaned positions\n",
        "            cleaned_positions.append(position)\n",
        "        else:\n",
        "            if last_valid_position is None:\n",
        "                # If there's no valid last position, accept the first valid one\n",
        "                cleaned_positions.append(position)\n",
        "                last_valid_position = position\n",
        "            else:\n",
        "                # Calculate the distance from the last valid position\n",
        "                distance = np.linalg.norm(position - last_valid_position)\n",
        "                if distance > distance_threshold:\n",
        "                    # Replace with empty array if the distance exceeds the threshold\n",
        "                    cleaned_positions.append(np.array([], dtype=np.float64))\n",
        "                else:\n",
        "                    cleaned_positions.append(position)\n",
        "                    last_valid_position = position\n",
        "\n",
        "    return cleaned_positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0wmKU-qq7zP"
      },
      "outputs": [],
      "source": [
        "MAX_DISTANCE_THRESHOLD = 500\n",
        "\n",
        "path = replace_outliers_based_on_distance(path, MAX_DISTANCE_THRESHOLD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXL4eqOTrASQ"
      },
      "outputs": [],
      "source": [
        "from sports.annotators.soccer import draw_paths_on_pitch\n",
        "\n",
        "annotated_frame = draw_pitch(CONFIG)\n",
        "annotated_frame = draw_paths_on_pitch(\n",
        "    config=CONFIG,\n",
        "    paths=[path],\n",
        "    color=sv.Color.WHITE,\n",
        "    pitch=annotated_frame)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36ccaec7"
      },
      "source": [
        "!pip install -q numpy==1.26.4\n",
        "!pip install -q onnxruntime-gpu==1.18.0 --index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}